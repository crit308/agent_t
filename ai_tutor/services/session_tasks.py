import logging
import asyncio
from uuid import UUID
from typing import Optional # Added Optional
from ai_tutor.dependencies import get_supabase_client
from ai_tutor.agents.session_analyzer_agent import analyze_session # Import the analysis function
# Import SessionAnalysis model if needed for storage later
from ai_tutor.agents.models import SessionAnalysis

logger = logging.getLogger(__name__)

async def queue_session_analysis(session_id: UUID, user_id: UUID, folder_id: Optional[UUID]):
    """The background task to run analysis and update KB."""
    logger.info(f"Background task started: Analyzing session {session_id}")
    supabase = None
    try:
        supabase = await get_supabase_client()

        # --- D-3 Refinement: Mark session as ended --- #
        # Check if already ended (redundant check with trigger, but safer)
        ended_check = await supabase.table("sessions").select("ended_at").eq("id", str(session_id)).maybe_single().execute()
        if ended_check.data and ended_check.data.get("ended_at") is not None:
             logger.info(f"Background task: Session {session_id} was already marked ended. Exiting task.")
             return # Exit if already ended

        logger.info(f"Marking session {session_id} as ended in DB.")
        # Use Supabase function for timestamp precision
        update_resp = await supabase.table("sessions").update({"ended_at": "now()"}).eq("id", str(session_id)).execute()
        # Check if update succeeded (response format depends on Supabase version)
        if not hasattr(update_resp, 'data') or not update_resp.data:
             # Log warning but proceed; maybe RLS prevented update?
             logger.warning(f"Failed to mark session {session_id} as ended (maybe already ended or RLS issue). Update response: {update_resp}. Analysis proceeding anyway.")

        # --- Call Analyzer --- #
        logger.info(f"Calling analyze_session for session {session_id}")
        # Pass None for context, as run config isn't strictly needed here unless deep tracing is desired
        text_summary, structured_analysis = await analyze_session(session_id, context=None)
        logger.info(f"Analysis completed for session {session_id}. Text Summary: {'Yes' if text_summary else 'No'}, Structured: {'Yes' if structured_analysis else 'No'}")

        # --- Append to KB if summary exists and folder_id is known --- #
        if text_summary and folder_id:
            logger.info(f"Attempting to append summary to KB for folder {folder_id}")
            try:
                # Call the RPC function
                rpc_params = {'target_folder_id': str(folder_id), 'new_summary_text': text_summary}
                rpc_resp = await supabase.rpc('append_to_knowledge_base', rpc_params)
                # Check rpc_resp for errors if the function returned status (currently returns void)
                # Supabase Python client v2 rpc calls don't throw exceptions on PG errors by default
                # We might need more robust error checking depending on function definition & client behavior
                logger.info(f"Successfully called append_to_knowledge_base RPC for folder {folder_id}. Response: {rpc_resp}")
            except Exception as rpc_err:
                 # Catch potential network errors or unexpected issues calling the RPC
                 logger.error(f"Failed to call append_to_knowledge_base RPC for folder {folder_id}: {rpc_err}", exc_info=True)
        elif not folder_id:
             logger.warning(f"Cannot append KB summary for session {session_id}: folder_id is unknown.")
        elif not text_summary:
             logger.warning(f"Cannot append KB summary for session {session_id}: No text summary generated by analyzer.")

        # --- (Optional) Store Structured Analysis --- #
        if structured_analysis:
            # Example: Store in a separate table or bucket (Placeholder)
            try:
                # Example: Assuming a table 'session_analysis_results' exists
                # analysis_dict = structured_analysis.model_dump(mode='json')
                # insert_resp = await supabase.table("session_analysis_results").insert(analysis_dict).execute()
                # if insert_resp.data:
                #     logger.info(f"Stored structured analysis data for session {session_id} successfully.")
                # else:
                #     logger.error(f"Failed to store structured analysis data for session {session_id}. Response: {insert_resp}")
                logger.info(f"Placeholder: Would store structured analysis data for session {session_id} here.")
            except Exception as store_err:
                logger.error(f"Failed to store structured analysis data for session {session_id}: {store_err}", exc_info=True)

        logger.info(f"Background task finished successfully for session {session_id}")

    except Exception as e:
        logger.error(f"Error in background analysis task for session {session_id}: {e}", exc_info=True) 