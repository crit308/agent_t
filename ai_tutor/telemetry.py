import time
import asyncio
from ai_tutor.dependencies import SUPABASE_CLIENT
from openai.types import CompletionUsage
from ai_tutor.context import TutorContext
from functools import wraps

# --- Background queue for Supabase writes ---
def enqueue(table: str, data: dict):
    if SUPABASE_CLIENT:
        async def write():
            SUPABASE_CLIENT.table(table).insert(data).execute()
        # Fire and forget
        asyncio.create_task(write())

def log_tool(fn):
    """
    Decorator that measures latency and writes an edge_logs row,
    *without* destroying the function_tool metadata.
    """
    @wraps(fn)
    async def wrapper(*args, **kwargs):
        start = time.perf_counter()
        res   = await fn(*args, **kwargs)
        ms    = int((time.perf_counter()-start)*1000)
        ctx   = args[0]               # every tool receives ctx first
        if SUPABASE_CLIENT:
            usage = getattr(res, "usage", None)
            # Determine session and user IDs from context
            sess_id = None
            user_id = None
            if hasattr(ctx, "context") and hasattr(ctx.context, "session_id"):
                sess_id = ctx.context.session_id
                user_id = ctx.context.user_id
            else:
                sess_id = getattr(ctx, "session_id", None)
                user_id = getattr(ctx, "user_id", None)
            enqueue("edge_logs", {
                "session_id": str(sess_id) if sess_id is not None else None,
                "user_id": str(user_id) if user_id is not None else None,
                "tool": fn.__name__,
                "latency_ms": ms,
                "prompt_tokens": getattr(usage, "prompt_tokens", None),
                "completion_tokens": getattr(usage, "completion_tokens", None),
                # Optional trace ID
                "trace_id": getattr(ctx, "trace_id", None),
            })
            # Persist context after every successful tool (still sync)
            if hasattr(ctx, "context") and isinstance(ctx.context, TutorContext):
                # Store updated context in the 'context_data' JSONB column
                SUPABASE_CLIENT.table("sessions").update({
                    "context_data": ctx.context.model_dump(mode='json')
                }).eq("id", str(ctx.context.session_id)).eq("user_id", str(ctx.context.user_id)).execute()
        return res
    # âœ¨ copy the JSON schema generated by @function_tool
    if hasattr(fn, "__ai_function_spec__"):
        wrapper.__ai_function_spec__ = fn.__ai_function_spec__
    return wrapper 