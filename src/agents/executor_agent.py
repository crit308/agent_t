import logging
from loguru import logger # Use loguru
import json
from pydantic import ValidationError

from ai_tutor.context import TutorContext as SessionContext
from ai_tutor.core.llm import LLMClient
# Switch to canonical models in ai_tutor.api_models
from ai_tutor.api_models import (
    InteractionResponseData,
    ExplanationResponse,
    QuestionResponse,
    FeedbackResponse,
    MessageResponse as DialogueResponse,  # Map Dialogue to MessageResponse
    UserModelState,
)
# Pull QuizQuestion from ai_tutor.agents.models
from ai_tutor.agents.models import QuizQuestion
# ResponseType isn't explicitly needed; if used later we can compute union
ResponseType = InteractionResponseData
# Import skills - Assume they exist or will be created
from ai_tutor.skills.explain_concept import explain_concept
from ai_tutor.skills.create_quiz import create_quiz # Assume exists
# from src.skills.evaluate_quiz import evaluate_quiz # Assume exists
# from src.skills.remediate_concept import remediate_concept # Assume exists
# from src.skills.update_user_model import update_user_model # Assume exists

# Use loguru logger directly
# logger = logging.getLogger(__name__) # Remove standard logging setup

# --- Executor Agent Prompt ---
# Define the detailed prompt structure here or load from a file
EXECUTOR_PROMPT_TEMPLATE = """
You are the Executor Agent in a pedagogical tutoring system. Your primary role is to select and execute the MOST APPROPRIATE pedagogical skill for the current turn, based on the learning context, and return a structured response.

**Context:**
*   **Learning Goal:** {learning_goal}
*   **Current Focus Objective:** {current_focus_objective}
*   **User Model State:** {user_model_state}
*   **Conversation History (Last 5 turns):** 
{conversation_history}
*   **User Input:** {user_input}

**Available Skills:**
1.  `explain_concept(topic: str, detail_level: str)`: Explains a concept. Use when introducing a new topic or clarifying based on user need.
2.  `create_quiz(topic: str, question_type: str, difficulty: str)`: Creates a single quiz question (e.g., multiple-choice) about a topic. Use after explaining a concept to check understanding.
3.  `evaluate_quiz(user_answer: Any, correct_answer: Any, question_details: dict)`: Evaluates the user's answer to a quiz question. Use immediately after the user answers a question generated by `create_quiz`.
4.  `remediate_concept(topic: str, misconceptions: list[str])`: Provides targeted remediation based on identified misunderstandings. Use after incorrect quiz answers or explicit user confusion.
5.  `update_user_model(topic: str, understanding_level: float, engagement_level: str)`: Updates the user model based on interaction. (Note: This skill might be implicitly handled or called internally after other skills).
6.  `dialogue(message: str)`: Provide a simple text message if no other skill is appropriate (e.g., greeting, transition).

**Your Task:**
1.  **Analyze Context:** Carefully review the learning goal, current focus, user model, history, and user input.
2.  **Select ONE Skill:** Choose the single most pedagogically sound skill to execute for this turn.
    *   If the user just agreed to start or needs the concept explained, use `explain_concept`.
    *   After explaining, check understanding with `create_quiz`.
    *   If the user provided an answer to a quiz, use `evaluate_quiz`.
    *   If evaluation shows misunderstanding, use `remediate_concept`.
    *   If unsure or transitioning, use `dialogue`.
3.  **Determine Interaction Status:** Decide the next state:
    *   `awaiting_user_input`: If the interaction requires user response (e.g., after explanation or question).
    *   `objective_complete`: If this interaction fulfills the current focus objective.
4.  **Format Output:** Construct a SINGLE JSON object containing the results. **DO NOT output ANY text outside this JSON object.**

**Output JSON Structure:**
Your response MUST be a single JSON object adhering to this structure:
{{
  "content_type": "explanation" | "question" | "feedback" | "dialogue" | "error", // Corresponds to skill used
  "data": {{ ... }}, // Structure matches the specific response type model (ExplanationResponse, QuestionResponse, FeedbackResponse, DialogueResponse)
  "user_model_state": {{ ... }}, // The complete, potentially updated user model state based on the interaction
  "status": "awaiting_user_input" | "objective_complete" // Your determined status
}}

**EXAMPLE Explanation Output:**
{{
  "content_type": "explanation",
  "data": {{
    "response_type": "explanation", // Add this field matching content_type
    "text": "The water cycle starts with evaporation...",
    "topic": "Evaporation", // Include relevant topic
    "detail_level": "beginner" // Include relevant detail level
    // Add segment_index and is_last_segment if implementing segmentation
  }},
  "user_model_state": {{ ... updated state ... }},
  "status": "awaiting_user_input"
}}

**EXAMPLE Question Output:**
{{
  "content_type": "question",
  "data": {{
     "response_type": "question", // Add this field matching content_type
     "question": {{ 
        "question_text": "What is evaporation?", 
        "options": ["Liquid to Gas", "Gas to Liquid", "Solid to Gas"], 
        "correct_answer": "Liquid to Gas", 
        "question_type": "multiple_choice" 
     }},
     "topic": "Evaporation" // Include relevant topic
  }},
  "user_model_state": {{ ... updated state ... }},
  "status": "awaiting_user_input"
}}

**Mandatory Actions:**
*   Choose ONE skill per turn.
*   Output ONLY the specified JSON object.
*   Ensure the `data` field structure matches the `content_type`.
*   Update the `user_model_state` thoughtfully based on the interaction.
*   Set the `status` field correctly.

Now, analyze the provided context and generate the JSON response for this turn.
"""

class ExecutorAgentError(Exception):
    """Custom exception for errors during executor execution."""
    pass

class ExecutorAgent:
    """
    The Executor Agent uses an LLM to decide which pedagogical skill to use
    based on the context and returns a structured JSON response.
    """
    def __init__(self):
        self.llm_client = LLMClient()

    async def run(self, context: SessionContext, user_input_text: str | None) -> tuple[InteractionResponseData, str]: # Return status too
        """
        Runs the executor agent for one interaction turn using an LLM call.

        Args:
            context: The current session context.
            user_input_text: The user's text input for this turn.

        Returns:
            A tuple containing:
                - InteractionResponseData: The structured response for the FE.
                - str: The status determined by the LLM ('awaiting_user_input' or 'objective_complete').

        Raises:
            ExecutorAgentError: If the LLM response is invalid or execution fails.
        """
        logger.info(f"ExecutorAgent running for session: {context.session_id}, user input: '{user_input_text}'")

        if not context.current_focus_objective:
            logger.error(f"Executor called without a focus objective. Session: {context.session_id}")
            # Return a default error response AND a default status
            error_data = DialogueResponse(response_type="dialogue", dialogue_text="I seem to have lost my train of thought. Could we try planning the lesson again?")
            user_model_state_dict = context.user_model_state.model_dump() if context.user_model_state else UserModelState().model_dump()
            response = InteractionResponseData(
                content_type="error", 
                data=error_data,
                user_model_state=user_model_state_dict
            )
            return response, "awaiting_user_input" # Default status for error

        # --- Prepare LLM Input ---
        learning_goal = context.learning_goal or "Not specified"
        focus_objective_str = str(context.current_focus_objective.model_dump()) if context.current_focus_objective else "None"
        user_model_str = str(context.user_model.model_dump()) if context.user_model else "None"
        # TODO: Implement actual conversation history retrieval
        history_str = "History not yet implemented." 
        user_input = user_input_text or "No user input (likely first turn for objective)."

        prompt = EXECUTOR_PROMPT_TEMPLATE.format(
            learning_goal=learning_goal,
            current_focus_objective=focus_objective_str,
            user_model_state=user_model_str,
            conversation_history=history_str,
            user_input=user_input
        )

        # --- Call LLM ---
        logger.debug(f"Executor LLM Prompt for session {context.session_id}:\n{prompt}")
        try:
            llm_response = await self.llm_client.chat(prompt, json_mode=True) # Request JSON mode
            response_content = llm_response.message.content
            logger.debug(f"Executor LLM Raw Response for session {context.session_id}: {response_content}")

            if not response_content:
                raise ExecutorAgentError("LLM returned empty content.")

            # --- Parse LLM JSON Response ---
            try:
                response_json = json.loads(response_content)
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse LLM JSON response for session {context.session_id}: {response_content}", exc_info=True)
                raise ExecutorAgentError(f"LLM did not return valid JSON: {e}") from e

            # --- Validate and Extract Fields ---
            content_type = response_json.get("content_type")
            data_dict = response_json.get("data")
            user_model_state_dict = response_json.get("user_model_state")
            status = response_json.get("status")

            if not all([content_type, data_dict, user_model_state_dict, status]):
                raise ExecutorAgentError(f"LLM JSON response missing required fields (content_type, data, user_model_state, status). Received: {response_json}")

            if status not in ["awaiting_user_input", "objective_complete"]:
                 logger.warning(f"LLM returned invalid status '{status}'. Defaulting to 'awaiting_user_input'. Session: {context.session_id}")
                 status = "awaiting_user_input"

            # --- PATCH: If content_type is explanation and 'message' is present, rename to 'text' ---
            if content_type == "explanation" and "message" in data_dict and "text" not in data_dict:
                data_dict["text"] = data_dict.pop("message")

            # --- Validate Data Structure based on Content Type ---
            # Note: We rely on the LLM prompt to ensure 'data' matches 'content_type'.
            # Adding Pydantic validation here provides robustness.
            validated_data: ExplanationResponse | QuestionResponse | FeedbackResponse | DialogueResponse | None = None
            try:
                # Add response_type to data if missing (for older model compatibility or LLM errors)
                if "response_type" not in data_dict:
                     data_dict["response_type"] = content_type # Assume it matches

                if content_type == "explanation":
                    validated_data = ExplanationResponse(**data_dict)
                elif content_type == "question":
                    # Ensure the nested question structure is handled if needed by Pydantic model
                    validated_data = QuestionResponse(**data_dict)
                elif content_type == "feedback":
                    validated_data = FeedbackResponse(**data_dict)
                elif content_type == "dialogue":
                     validated_data = DialogueResponse(**data_dict)
                # Handle 'error' content type - maybe return DialogueResponse?
                elif content_type == "error":
                     error_text = data_dict.get("message", "An error occurred during processing.")
                     validated_data = DialogueResponse(response_type="dialogue", dialogue_text=error_text)
                else:
                    raise ExecutorAgentError(f"LLM returned unsupported content_type: {content_type}")

            except ValidationError as e:
                logger.error(f"LLM data validation failed for content_type '{content_type}'. Data: {data_dict}. Error: {e}", exc_info=True)
                raise ExecutorAgentError(f"LLM response data validation failed: {e}") from e

            # --- Validate User Model State ---
            try:
                validated_user_model = UserModelState(**user_model_state_dict)
            except ValidationError as e:
                 logger.error(f"LLM user_model_state validation failed. State: {user_model_state_dict}. Error: {e}", exc_info=True)
                 raise ExecutorAgentError(f"LLM response user_model_state validation failed: {e}") from e


            # --- Construct Final Response (excluding status) ---
            interaction_response = InteractionResponseData(
                content_type=content_type, # Use the validated/parsed content type
                data=validated_data,
                user_model_state=validated_user_model.model_dump() # Use validated model dump
            )

            # --- Update Context (Optional but recommended) ---
            # Update the user model in the context *before* returning
            context.user_model = validated_user_model
            logger.debug(f"User model updated in context for session {context.session_id}")

            # TODO: Decide if focus objective should be cleared based on 'status' == 'objective_complete'
            if status == "objective_complete":
                logger.info(f"Objective '{context.current_focus_objective.objective_topic}' marked complete by Executor for session {context.session_id}.")
                # context.current_focus_objective = None # Planner might handle this

            logger.info(f"Executor successfully generated response for session {context.session_id}. Type: {interaction_response.content_type}")
            return interaction_response, status # Return both

        except Exception as e:
            logger.exception(f"Error during ExecutorAgent LLM execution for session {context.session_id}: {e}", exc_info=True)
            # Wrap specific errors or re-raise generic for the wrapper
            if isinstance(e, ExecutorAgentError):
                raise e 
            else:
                raise ExecutorAgentError(f"LLM call or processing failed: {e}") from e


# --- Standalone function wrapper --- 
async def run_executor(context: SessionContext, user_input_text: str | None) -> InteractionResponseData: # Only return InteractionResponseData
    """
    Functional wrapper to instantiate and run the ExecutorAgent.
    Handles agent execution, basic error response generation, and status logging.
    The status determined by the LLM is logged but NOT included in the returned object.
    """
    agent = ExecutorAgent()
    try:
        # Agent's run now returns response AND status
        interaction_response, status = await agent.run(context, user_input_text) 
        # Log successful response details here - Removed status access
        logger.info(f"Executor successfully generated response for session {context.session_id}. Type: {interaction_response.content_type}")
        return interaction_response # Return only the InteractionResponseData

    except ExecutorAgentError as e:
        logger.error(f"ExecutorAgent Error for session {context.session_id}: {e}", exc_info=False) 
        # Create error response
        error_data = DialogueResponse(response_type="dialogue", dialogue_text="I encountered an issue processing that step. Let's try again.")
        user_model_state_dict = context.user_model.model_dump() if context.user_model else UserModelState().model_dump()
        return InteractionResponseData(
            content_type="error", 
            data=error_data,
            user_model_state=user_model_state_dict
        )
    except Exception as e:
        logger.exception(f"Unexpected error in run_executor for session {context.session_id}: {e}", exc_info=True)
        # Create generic error response
        error_data = DialogueResponse(response_type="dialogue", dialogue_text="An unexpected error occurred. Please try again.")
        user_model_state_dict = context.user_model.model_dump() if context.user_model else UserModelState().model_dump()
        return InteractionResponseData(
            content_type="error", 
            data=error_data,
            user_model_state=user_model_state_dict
        ) 